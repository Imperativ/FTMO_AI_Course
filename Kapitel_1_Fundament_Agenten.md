# ğŸ“˜ Kapitel 1 â€“ Fundament: Denken wie ein KI-Agenten-Architekt

**Lernziel:**
Nach dieser Lektion verstehst du, was ein â€Agentâ€œ im Kontext moderner KI-Systeme ist, wie sich ChatGPT-Agenten konzeptionell unterscheiden von klassischen Trading-Bots â€“ und wie du dieses Wissen nutzt, um ein eigenes, steuerbares System aufzubauen.

---

## ğŸ§© Abschnitt 1 â€“ Was ist ein Agent?

Ein **Agent** ist kein Wesen mit â€Intelligenzâ€œ im menschlichen Sinn, sondern ein **System, das auf Basis von Wahrnehmung, Zustand und Ziel entscheidet, welche Aktion es ausfÃ¼hrt**.
Er reagiert also auf eine Umgebung (Umweltzustand) mit einer Handlung (Aktion), die ein Ziel verfolgt (Reward oder Erfolgskriterium).

Ein klassisches Agenten-Schema besteht aus:

- **Sensoren / Input:** Was der Agent wahrnimmt (z. B. Marktdaten, Zeit, Kontostand).
- **Zustand / Speicher:** Was er Ã¼ber die Welt weiÃŸ oder erinnert.
- **Aktoren / Output:** Was er tun kann (z. B. ein Signal senden, eine Order vorschlagen).
- **Ziel / Policy:** Wie er entscheidet, was â€gutâ€œ ist (z. B. Profit maximieren, Drawdown vermeiden).

In der Sprache von LLM-basierten Agenten ersetzt das Modell den **Entscheidungsteil** durch natÃ¼rliche Sprache.
Statt EntscheidungsbÃ¤ume in Code zu gieÃŸen, beschreibst du Regeln in Textform:

> â€Analysiere die letzten 12 Stunden BTC/USD, erkenne Trendrichtung, berechne RSI und schlage Long oder Short vor â€“ aber nur, wenn der Drawdown unter 2â€¯% bleibt.â€œ

Damit Ã¼bernimmst du das Denken â€“ die Logik bleibt aber algorithmisch steuerbar.

---

## ğŸ’¬ Abschnitt 2 â€“ Warum ChatGPT-Agenten keine â€Trading-Botsâ€œ sind

Ein ChatGPT-Agent kann **kontextualisieren**, **lernen aus Feedback** und **natÃ¼rliche Sprache als Schnittstelle** nutzen.
Er kann aber **nicht autonom handeln** â€“ und das ist auch gut so.
FÃ¼r FTMO-Zwecke willst du einen _Assistenzagenten_:

- Er bewertet Marktsituationen.
- Erstellt Handlungsempfehlungen.
- Gibt RisikoabschÃ¤tzungen.
- Und meldet sie Ã¼ber einen Workflow (z.â€¯B. Telegram) an dich.

Die Entscheidung bleibt bei dir â€“ so umgehst du regulatorische Probleme und trainierst zugleich, die KI als Partner zu nutzen.

---

## âš™ï¸ Abschnitt 3 â€“ Der minimale Entscheidungs-Loop

In n8n kannst du diesen Loop spÃ¤ter als Workflow darstellen:

```
[Webhook Trigger]
   â†“
[Get Market Data]  â† Sensor
   â†“
[LLM Node]         â† Entscheidung
   â†“
[Risk Calculator]  â† Zustand / Policy
   â†“
[Send Telegram Msg]â† Aktion
```

Dieser Ablauf ist die DNA deines kÃ¼nftigen Agenten.
SpÃ¤ter fÃ¼gen wir Persistenz (Speicher) und Selbstbewertung (Feedback-Loop) hinzu.

---

## ğŸ§  Abschnitt 4 â€“ Theoretische BrÃ¼cke: RationalitÃ¤t und Unsicherheit

KÃ¼nstliche Agenten operieren unter **Unsicherheit** â€“ sie kennen die Zukunft nicht, sie schÃ¤tzen sie.
Darum gilt: _Ein intelligenter Agent ist einer, der seine Unsicherheit sinnvoll behandelt._
Das ist im Trading entscheidend.
Wir werden LLMs so nutzen, dass sie Wahrscheinlichkeiten und RisikoqualitÃ¤ten beschreiben, nicht absolute Wahrheiten.
Das Ergebnis ist kein â€Signalâ€œ im Sinne eines Dogmas, sondern eine _strukturierte Wahrscheinlichkeit_.

---

## ğŸ§© Abschnitt 5 â€“ Mini-Praxis: Dein erster Agent in Gedanken

1. Starte das aktuelle LLM-Modell Ã¼ber die API oder die OberflÃ¤che.
2. Gib folgenden Prompt ein:

```
Du bist ein Trading-Analyse-Agent.
Du erhÃ¤ltst Marktdaten (Open, High, Low, Close, Volume) fÃ¼r BTC/USD.
Analysiere sie, nenne Trendrichtung, Momentum und mÃ¶gliche Entry-Zonen.
Verwende dabei ein Risikomanagement mit maximal 2â€¯% Verlust pro Trade.
```

3. Lies die Antwort wie einen Bericht eines Assistenten â€“ nicht als Order.
4. Beobachte: ErklÃ¤rt der Agent seine Unsicherheit? Nutzt er Prozentangaben?
   Wenn nicht, Ã¤ndere den Prompt und fordere explizit â€SchÃ¤tze Wahrscheinlichkeitenâ€œ.

---

## ğŸ§­ Abschnitt 6 â€“ Reflexion

- Wo liegt der Unterschied zwischen einem deterministischen Programm und einem LLM-Agenten?
- Welche Risiken entstehen, wenn man einem Sprachmodell zu viel Entscheidungshoheit gibt?
- Wie wÃ¼rdest du den Agenten â€vorsichtigerâ€œ machen, ohne seine ReaktionsfÃ¤higkeit zu zerstÃ¶ren?

---

## ğŸ§© Abschnitt 7 â€“ Hausaufgabe / Experiment

Erstelle in n8n einen einfachen Workflow mit einem **Webhook Trigger** und einem **HTTP Request Node**.
Schick Ã¼ber den Webhook einen JSON-Payload mit einem Mini-Prompt (z. B. â€Was denkst du Ã¼ber EUR/USD heute?").
Lass dir die Antwort per **Telegram Node** an dich senden.

Du hast damit deinen ersten funktionierenden Kommunikations-Loop gebaut:
Du (Mensch) â†’ n8n (System) â†’ LLM (Denker) â†’ Telegram (Antwortkanal).

---

## ğŸ› ï¸ Abschnitt 8 â€“ Universelle Debug-Strategien fÃ¼r alle Kapitel

### JSON-Explorer Function

Wenn du nicht weiÃŸt, welche Daten in einem Node ankommen:

```javascript
// Zeige komplette Datenstruktur
console.log("=== DEBUG START ===");
console.log("Input Items Count:", $input.all().length);
console.log("First Item:", JSON.stringify($input.first(), null, 2));
console.log("All JSON keys:", Object.keys($json || {}));
console.log("=== DEBUG END ===");
return [$json];
```

### Error-Handling Template

FÃ¼r kritische Nodes:

```javascript
try {
  // Deine Logik hier
  const result = doSomething($json);
  return [{ success: true, data: result }];
} catch (error) {
  return [
    {
      success: false,
      error: error.message,
      timestamp: new Date().toISOString(),
      input: $json,
    },
  ];
}
```

### Workflow-Monitoring Checkliste

- Execution-History regelmÃ¤ÃŸig prÃ¼fen (n8n â†’ Executions)
- Failed Executions analysieren: Logs â†’ Error Details
- Performance: Lange Laufzeiten identifizieren
- Telegram-Alerts bei kritischen Fehlern einbauen

---

## âœ… Zusammenfassung

Nach Kapitel 1 weiÃŸt du:

- was ein Agent konzeptionell ist,
- wo LLM-basierte Agenten sich unterscheiden,
- wie ein n8n-Workflow als Denk-Loop funktioniert,
- und welche Debug-Strategien dir bei Problemen helfen.

In Kapitel 2 werden wir diesen Loop konkretisieren und **n8n praktisch einrichten** â€“ mit deinem ersten lauffÃ¤higen Flow, der Daten verarbeitet statt nur Text.
