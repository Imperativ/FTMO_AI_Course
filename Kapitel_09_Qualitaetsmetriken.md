# ğŸ“˜ Kapitel 9 â€“ QualitÃ¤tsmetriken und kontinuierliche Verbesserung

**Lernziel:**
Nach dieser Lektion kannst du aus Logs und Feedbacks automatisch **Leistungsmetriken** generieren.
Du lernst, wie du Trefferquote, Fehlerrate, Latenz und Tokenverbrauch berechnest und wie du daraus ableitest, wo dein System optimiert werden sollte.

---

## ğŸ§© Abschnitt 1 â€“ Warum QualitÃ¤tsmetriken entscheidend sind

Ein Agent ohne MessgrÃ¶ÃŸen ist wie ein Trader ohne Statistik.
Ohne Zahlen bleibt Leistung GefÃ¼hlssache â€“ und das fÃ¼hrt zu FehleinschÃ¤tzungen.

QualitÃ¤tsmetriken erlauben dir, systematisch zu prÃ¼fen:

- Arbeitet der Agent konsistent?
- Verbessern sich Entscheidungen Ã¼ber Zeit?
- Lohnt sich eine Prompt- oder ParameterÃ¤nderung?
- Wie stabil ist der Workflow bei hoher Last?

Ziel: Objektive, wiederholbare Beurteilung statt subjektiver EindrÃ¼cke.

---

## âš™ï¸ Abschnitt 2 â€“ Welche Metriken wichtig sind

**PrimÃ¤re Metriken (Leistung):**

- `winrate` â€“ Trefferquote (TP vs. SL)
- `expectancy` â€“ Durchschnittsgewinn pro Trade
- `latency_ms` â€“ durchschnittliche Laufzeit pro Run
- `error_rate` â€“ Anteil fehlerhafter AusfÃ¼hrungen
- `consistency` â€“ Varianz der Ergebnisse zwischen Tagen

**SekundÃ¤re Metriken (Kosten & Effizienz):**

- `token_usage` â€“ Verbrauchte Tokens pro Analyse
- `cost_per_decision` â€“ geschÃ¤tzte API-Kosten
- `retry_count` â€“ wie oft ein Workflow wiederholt wurde

Alle Metriken werden aus bestehenden Logs (Kapitel 5â€“8) berechnet.

---

## ğŸ§  Abschnitt 3 â€“ Berechnung von Metriken in n8n

Du kannst n8n direkt zur Auswertung verwenden.
Ein **Data Store Query + Function Node** reicht oft schon aus.

**Function-Node Beispiel:**

```javascript
const items = $input.all();
const metrics = {
  total: items.length,
  wins: 0,
  losses: 0,
  retries: 0,
  totalTokens: 0,
  totalDuration: 0,
};

for (const i of items) {
  const j = i.json;
  if (j.outcome === "TP") metrics.wins++;
  if (j.outcome === "SL") metrics.losses++;
  metrics.retries += j.retry_count || 0;
  metrics.totalTokens += j.token_usage || 0;
  metrics.totalDuration += j.latency_ms || 0;
}

metrics.winrate = metrics.total ? metrics.wins / metrics.total : 0;
metrics.avgDuration = metrics.total ? metrics.totalDuration / metrics.total : 0;
metrics.avgTokens = metrics.total ? metrics.totalTokens / metrics.total : 0;

return [metrics];
```

**Debugging-Tipp:**
Teste jede Metrik einzeln. Lass dir mit `console.log(metrics)` Zwischenschritte anzeigen, um Rundungsfehler und leere Felder frÃ¼h zu erkennen.

---

## ğŸ§© Abschnitt 4 â€“ Automatische QualitÃ¤tsreports

Mit n8n kannst du regelmÃ¤ÃŸige QualitÃ¤tsauswertungen automatisch generieren lassen.

**Beispiel-Flow:**

```
[Cron â†’ Query Data Store]
   â†“
[Function â†’ Metrics Calculation]
   â†“
[LLM Node â†’ Natural-Language Summary]
   â†“
[Telegram / E-Mail Report]
```

**Beispieltext im LLM-Node:**

```
Analysiere folgende Kennzahlen:
Winrate: 0.63
Average Latency: 2.4s
Error Rate: 0.07
Gib eine kurze qualitative Bewertung und Handlungsempfehlung.
```

So bekommst du tÃ¤glich einen â€Agent Performance Reportâ€œ â€“ kompakt, verstÃ¤ndlich und aus deinen echten Daten berechnet.

---

## ğŸ’¡ Abschnitt 5 â€“ Debugging von Metriken

Fehler in Statistiken sind tÃ¼ckisch, weil sie selten als â€Fehlerâ€œ auffallen.
Beachte daher:

### ğŸ” Tipp 1: â€Check for nullsâ€œ

In Function-Nodes immer prÃ¼fen:

```javascript
if (j.winrate == null) throw new Error("Winrate not calculated");
```

### ğŸ” Tipp 2: â€Cross-Validateâ€œ

Vergleiche deine Winrate mit dem tatsÃ¤chlichen VerhÃ¤ltnis in der Datenbank:

```sql
SELECT COUNT(*) FILTER (WHERE outcome='TP')::float / COUNT(*) FROM ftmo_signals;
```

(n8n kann SQL-Queries an externe Datenbanken ausfÃ¼hren.)

### ğŸ” Tipp 3: â€Version Taggingâ€œ

Speichere in jeder Metrik den Prompt- oder Strategiestand:

```json
{ "winrate": 0.63, "strategy_version": "v1.3" }
```

Damit kannst du spÃ¤tere Ã„nderungen korrekt zuordnen.

---

## âš™ï¸ Abschnitt 6 â€“ Visualisierung der Agentenleistung

Nutze Tools wie **Grafana**, **Metabase** oder **n8n-Dashboards**, um Metriken visuell darzustellen.
Alternativ kannst du per Function-Node HTML-Reports erzeugen.

**Mini-Beispiel:**

```javascript
const data = $json;
return [
  {
    html: `
  <h3>Agenten-Performance</h3>
  <ul>
    <li>Winrate: ${(data.winrate * 100).toFixed(2)}%</li>
    <li>Durchschnittliche Dauer: ${data.avgDuration.toFixed(0)} ms</li>
    <li>Tokenverbrauch: ${data.avgTokens.toFixed(1)}</li>
  </ul>
  `,
  },
];
```

AnschlieÃŸend â†’ **E-Mail Node** â†’ â€HTML formatâ€œ aktivieren.

---

## ğŸ§© Abschnitt 7 â€“ Praxis: Automatischer QualitÃ¤tsreport

1. Erstelle in n8n einen Cron-getriggerten Workflow (z.â€¯B. tÃ¤glich um 18:00 Uhr).
2. Lies den Data Store `ftmo_signals` aus.
3. Berechne Metriken mit Function-Node.
4. Sende den Report als:
   - Telegram-Nachricht (Kurzfassung)
   - E-Mail mit HTML-Report
5. Logge jede Report-AusfÃ¼hrung mit `timestamp` und `metrics_id`.

**Debugging-Hinweis:**
Teste Report-Flows mit kleinem Query-Limit (`limit: 5`), um Performance-Probleme und Syntaxfehler frÃ¼h zu erkennen.

---

## ğŸ§­ Abschnitt 8 â€“ Reflexion

- Welche Metrik hat fÃ¼r dich den hÃ¶chsten praktischen Wert?
- Wann gilt eine Winrate als â€verlÃ¤sslich" â€“ 20 Trades oder 200?
- Wie kÃ¶nntest du das Feedback aus dem Report nutzen, um Prompts oder Parameter anzupassen?

---

## ğŸ§© Abschnitt 9 â€“ Hausaufgabe / Experiment

1. Erstelle deinen automatischen QualitÃ¤tsreport.
2. Miss mindestens drei Tage lang Metriken.
3. PrÃ¼fe, ob sich Winrate oder Laufzeit verÃ¤ndern.
4. Notiere in deiner Kursmappe:
   - mÃ¶gliche Ursachen
   - geplante Anpassungen
   - beobachtete Verbesserungen
5. Optional: Lasse das LLM-Modell deine Reports selbst interpretieren (Meta-Analyse).

---

## ğŸš¨ Abschnitt 10 â€“ QualitÃ¤tsmetriken Debugging

### HÃ¤ufige Metriken-Berechnungsfehler

**Problem:** Falsche Winrate-Berechnungen
**Debug-Strategie:**

```javascript
// Robuste Winrate-Berechnung mit Validation
const calculateWinrateRobust = (trades) => {
  if (!Array.isArray(trades) || trades.length === 0) {
    console.warn("Invalid trades data for winrate calculation");
    return { winrate: 0, error: "No valid trades data" };
  }

  const validTrades = trades.filter(
    (trade) => trade.outcome === "TP" || trade.outcome === "SL",
  );

  if (validTrades.length === 0) {
    console.warn("No completed trades found");
    return { winrate: 0, error: "No completed trades" };
  }

  const wins = validTrades.filter((trade) => trade.outcome === "TP").length;
  const winrate = wins / validTrades.length;

  console.log(
    `Winrate calculation: ${wins}/${validTrades.length} = ${winrate.toFixed(4)}`,
  );

  return {
    winrate: Math.round(winrate * 10000) / 10000, // 4 Dezimalstellen
    wins,
    total: validTrades.length,
    invalid_trades: trades.length - validTrades.length,
  };
};
```

### Statistische Signifikanz prÃ¼fen

**Problem:** Zu kleine Stichproben fÃ¼hren zu falschen SchlÃ¼ssen
**Validation-Framework:**

```javascript
// Statistische Signifikanz-PrÃ¼fung
const validateStatisticalSignificance = (metrics, confidenceLevel = 0.95) => {
  const minSampleSize = 30; // Mindestanzahl fÃ¼r Normalverteilung
  const criticalValue = confidenceLevel === 0.95 ? 1.96 : 2.58; // 95% oder 99%

  const results = {
    valid: true,
    warnings: [],
    confidence_intervals: {},
  };

  // PrÃ¼fe Sample Size
  if (metrics.total < minSampleSize) {
    results.valid = false;
    results.warnings.push(
      `Sample size too small: ${metrics.total} < ${minSampleSize}`,
    );
  }

  // Berechne Konfidenzintervall fÃ¼r Winrate
  if (metrics.winrate !== undefined) {
    const p = metrics.winrate;
    const n = metrics.total;
    const standardError = Math.sqrt((p * (1 - p)) / n);
    const marginOfError = criticalValue * standardError;

    results.confidence_intervals.winrate = {
      lower: Math.max(0, p - marginOfError),
      upper: Math.min(1, p + marginOfError),
      margin_of_error: marginOfError,
    };

    if (marginOfError > 0.1) {
      // 10% Margin ist zu hoch
      results.warnings.push(
        `Winrate confidence interval too wide: Â±${(marginOfError * 100).toFixed(1)}%`,
      );
    }
  }

  return results;
};
```

### Performance-Metriken Anomalie-Detection

**Problem:** Schleichende Performance-Degradation Ã¼bersehen
**Monitoring-System:**

```javascript
// Anomalie-Detection fÃ¼r Performance-Metriken
const detectPerformanceAnomalies = (currentMetrics, historicalData) => {
  const anomalies = [];
  const thresholds = {
    latency_increase: 2.0, // 200% ErhÃ¶hung
    winrate_drop: 0.15, // 15 Prozentpunkte
    error_rate_spike: 0.1, // 10% Fehlerrate
  };

  // Berechne historische Baselines
  const baseline = calculateBaseline(historicalData);

  // PrÃ¼fe Latenz-Anomalien
  if (
    currentMetrics.avgDuration >
    baseline.avgDuration * thresholds.latency_increase
  ) {
    anomalies.push({
      type: "latency_spike",
      current: currentMetrics.avgDuration,
      baseline: baseline.avgDuration,
      increase_factor: currentMetrics.avgDuration / baseline.avgDuration,
      severity: "high",
    });
  }

  // PrÃ¼fe Winrate-Anomalien
  if (currentMetrics.winrate < baseline.winrate - thresholds.winrate_drop) {
    anomalies.push({
      type: "winrate_drop",
      current: currentMetrics.winrate,
      baseline: baseline.winrate,
      drop: baseline.winrate - currentMetrics.winrate,
      severity: "critical",
    });
  }

  // PrÃ¼fe Error-Rate-Anomalien
  if (currentMetrics.error_rate > thresholds.error_rate_spike) {
    anomalies.push({
      type: "error_spike",
      current: currentMetrics.error_rate,
      threshold: thresholds.error_rate_spike,
      severity: "high",
    });
  }

  return {
    anomalies,
    baseline,
    alert_required: anomalies.some((a) => a.severity === "critical"),
  };
};

const calculateBaseline = (historicalData) => {
  const recentData = historicalData.slice(-30); // Letzte 30 EintrÃ¤ge

  return {
    avgDuration:
      recentData.reduce((sum, d) => sum + d.avgDuration, 0) / recentData.length,
    winrate:
      recentData.reduce((sum, d) => sum + d.winrate, 0) / recentData.length,
    error_rate:
      recentData.reduce((sum, d) => sum + d.error_rate, 0) / recentData.length,
  };
};
```

### Metriken-Dashboard Generator

**Problem:** Metriken sind schwer zu visualisieren
**HTML-Report-Generator:**

```javascript
// Automatischer HTML-Dashboard-Generator
const generateMetricsDashboard = (metrics, anomalies) => {
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
        <title>FTMO Agent Metrics Dashboard</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .metric { background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }
            .good { border-left: 5px solid #4CAF50; }
            .warning { border-left: 5px solid #FF9800; }
            .critical { border-left: 5px solid #F44336; }
            .number { font-size: 24px; font-weight: bold; }
        </style>
    </head>
    <body>
        <h1>ğŸ¤– FTMO Agent Performance Dashboard</h1>
        <p>Generated: ${new Date().toISOString()}</p>

        <div class="metric ${getMetricClass(metrics.winrate, 0.6)}">
            <h3>ğŸ“ˆ Win Rate</h3>
            <div class="number">${(metrics.winrate * 100).toFixed(2)}%</div>
            <p>${metrics.wins}/${metrics.total} trades</p>
        </div>

        <div class="metric ${getLatencyClass(metrics.avgDuration)}">
            <h3>âš¡ Average Latency</h3>
            <div class="number">${metrics.avgDuration.toFixed(0)}ms</div>
        </div>

        <div class="metric ${getErrorRateClass(metrics.error_rate || 0)}">
            <h3>ğŸš¨ Error Rate</h3>
            <div class="number">${((metrics.error_rate || 0) * 100).toFixed(2)}%</div>
        </div>

        ${
          anomalies && anomalies.length > 0
            ? `
        <h2>âš ï¸ Detected Anomalies</h2>
        ${anomalies
          .map(
            (anomaly) => `
        <div class="metric critical">
            <h3>${anomaly.type.toUpperCase()}</h3>
            <p>Severity: ${anomaly.severity}</p>
            <p>Current: ${JSON.stringify(anomaly.current)}</p>
        </div>
        `,
          )
          .join("")}
        `
            : "<p>âœ… No anomalies detected</p>"
        }

    </body>
    </html>
  `;

  return html;
};

const getMetricClass = (value, threshold) => {
  if (value >= threshold) return "good";
  if (value >= threshold * 0.8) return "warning";
  return "critical";
};

const getLatencyClass = (latency) => {
  if (latency < 1000) return "good";
  if (latency < 3000) return "warning";
  return "critical";
};

const getErrorRateClass = (errorRate) => {
  if (errorRate < 0.05) return "good";
  if (errorRate < 0.1) return "warning";
  return "critical";
};
```

---

## âœ… Zusammenfassung

Nach Kapitel 9 kannst du:

- Metriken automatisiert berechnen und loggen,
- Agentenleistung objektiv bewerten,
- Fehler in Statistiken erkennen und beheben,
- Anomalien automatisch detektieren,
- und Reports fÃ¼r kontinuierliche Verbesserung nutzen.

Im nÃ¤chsten Kapitel (10) lernst du, wie du deinen gesamten Agentenprozess dokumentierst und versionierst â€“ damit er als professionelles System nachvollziehbar, wartbar und auditierbar bleibt.
