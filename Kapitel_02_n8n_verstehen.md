# ğŸ“˜ Kapitel 2 â€“ n8n verstehen und vorbereiten

**Lernziel:**
Nach dieser Lektion kannst du n8n selbststÃ¤ndig bedienen, einfache Workflows erstellen und verstehen, wie Daten durch Nodes flieÃŸen. Du lernst, n8n als die â€Verkabelungsebeneâ€œ deines kÃ¼nftigen Trading-Agenten zu sehen.

---

## ğŸ§© Abschnitt 1 â€“ Was n8n eigentlich ist

n8n ist ein **Workflow-Automatisierungssystem**, das Daten zwischen Diensten verschiebt und dabei eigene Logik ausfÃ¼hrt.
Stell es dir wie ein **digitales Mischpult** vor: Jeder Node ist ein Regler oder Schalter, der Eingaben verÃ¤ndert, kombiniert oder weiterleitet.

Im Gegensatz zu â€no-codeâ€œ-Tools wie Zapier ist n8n **open source**, kann lokal laufen und erlaubt **volle Kontrolle Ã¼ber Logik, Variablen und API-Zugriffe**.
FÃ¼r unsere Zwecke ist das entscheidend: Wir kÃ¶nnen damit nicht nur APIs ansprechen, sondern auch LLM-Prompts verarbeiten, Ergebnisse speichern und mit Risiko-Parametern anreichern.

---

## âš™ï¸ Abschnitt 2 â€“ Installation und Start

**Option A: Desktop-App (empfohlen fÃ¼r Einstieg)**

1. Lade die aktuelle Version unter [https://n8n.io/download](https://n8n.io/download) herunter.
2. Starte die Anwendung, wÃ¤hle einen Arbeitsordner (z.â€¯B. `FTMO-Agent/n8n-workspace/`).
3. Nach dem Start erreichst du die OberflÃ¤che im Browser unter
   ```
   http://localhost:5678
   ```

**Option B: Docker (fÃ¼r fortgeschrittene Nutzung)**
Wenn du n8n dauerhaft auf einem Server laufen lassen willst:

```bash
docker run -it --rm   -p 5678:5678   -v ~/.n8n:/home/node/.n8n   n8nio/n8n
```

Beide Varianten sind funktional identisch; Docker eignet sich spÃ¤ter, wenn du den Agenten dauerhaft laufen lassen willst.

---

## ğŸ’¡ Abschnitt 3 â€“ Der Aufbau der OberflÃ¤che

Sobald n8n lÃ¤uft, siehst du drei Hauptbereiche:

1. **Node-Canvas:** Hier verbindest du einzelne FunktionsblÃ¶cke (Nodes) miteinander.
2. **Sidebar:** Liste aller verfÃ¼gbaren Nodes â€“ sortiert nach Kategorie (Trigger, Webhook, HTTP Request, Function usw.).
3. **Execution-Panel:** Zeigt, welche Daten ein Node empfangen und ausgegeben hat â€“ dein wichtigstes Debug-Werkzeug.

Ein Workflow ist immer eine **gerichtete Kette von Nodes**, in der jede Stufe Daten weiterreicht.

---

## ğŸ§© Abschnitt 4 â€“ Dein erster Workflow

Wir beginnen mit einem kleinen Test:
Ein Workflow, der jede Stunde eine kurze Nachricht an dich sendet.

1. Erstelle einen neuen Workflow.
2. Ziehe einen **Cron-Node** auf die FlÃ¤che.
   - Einstellung: â€Every hourâ€œ.
3. FÃ¼ge einen **Function-Node** hinzu.
   - Code:
     ```javascript
     return [{ message: "n8n lÃ¤uft stabil und wartet auf Befehle." }];
     ```
4. FÃ¼ge einen **Telegram Node** hinzu (unter â€Messagingâ€œ).
   - Trage deinen Bot-Token und deine Chat-ID ein.
   - Verwende `{{$json["message"]}}` als Nachrichtentext.
5. Verbinde die Nodes: **Cron â†’ Function â†’ Telegram**.
6. Speichere und aktiviere den Workflow.

Ergebnis: Dein Telegram-Bot meldet sich stÃ¼ndlich mit einem Statussignal.
Das ist dein â€Herzschlagâ€œ â€“ ein kleiner, aber sehr nÃ¼tzlicher Testlauf, bevor du komplexe Flows baust.

---

## ğŸ”§ Abschnitt 5 â€“ Datenfluss und Debugging

Klicke nach einer AusfÃ¼hrung auf den **Function-Node** und schau dir im rechten Panel die JSON-Daten an.
Das Prinzip ist immer gleich:

- Eingabe (Input) â†’ Verarbeitung â†’ Ausgabe (Output).
- Jede Ausgabe wird automatisch an den nÃ¤chsten Node Ã¼bergeben.

Wenn du den Output eines Nodes inspizieren kannst, verstehst du praktisch jeden n8n-Workflow.
Die FÃ¤higkeit, Flows zu _lesen_, ist fast wichtiger als sie zu _bauen_.

---

## ğŸ§  Abschnitt 6 â€“ Theoretischer Unterbau: Daten als Sprache

n8n spricht JSON.
Jeder Node erzeugt, verÃ¤ndert oder liest **Datenobjekte**, die so aussehen:

```json
{ "symbol": "BTCUSD", "price": 68235.4, "volume": 1943 }
```

LLMs verstehen ebenfalls JSON, wenn du es korrekt formst.
Damit bilden n8n (Logik-Layer) und LLM (Analyse-Layer) eine **gemeinsame Sprache**.
SpÃ¤ter wirst du z.â€¯B. Marktdaten als JSON einspeisen, das LLM analysiert sie, und das Ergebnis lÃ¤uft wieder als JSON zurÃ¼ck â€“ etwa:

```json
{ "trend": "bullish", "confidence": 0.73, "recommendation": "long" }
```

---

## ğŸ§© Abschnitt 7 â€“ Mini-Praxis: â€Ping den GPT-Agentenâ€œ

1. Erstelle einen neuen Workflow.
2. Nodeâ€¯1: **Webhook** â€“ Methode `POST`.
3. Nodeâ€¯2: **HTTP Request** â€“ Ziel `https://api.openai.com/v1/chat/completions`.
4. Authentifiziere dich mit deinem OpenAI-Key.
5. Sende folgenden Body:
   ```json
   {
     "model": "aktuelles LLM Modell",
     "messages": [
       { "role": "system", "content": "Du bist ein Trading-Assistent." },
       {
         "role": "user",
         "content": "Wie ist die aktuelle Stimmung zu BTC/USD?"
       }
     ]
   }
   ```
6. Ausgabe prÃ¼fen â†’ JSON-Pfad `choices[0].message.content` â†’ Telegram-Node â†’ dir selbst senden.

Damit hast du **deinen ersten LLM-Aufruf Ã¼ber n8n** realisiert.
Es ist der Grundbaustein aller kommenden Agenten.

---

## ğŸ§­ Abschnitt 8 â€“ Reflexion

- Wie unterscheidet sich n8n von einer klassischen Programmiersprache?
- Welche Vorteile bringt der visuelle Aufbau gegenÃ¼ber Code?
- Wie wÃ¼rdest du Fehlermeldungen oder API-Timeouts im Workflow abfangen?

Notiere Antworten in deiner Zed-Mappe, sie helfen spÃ¤ter bei der Fehlerbehandlung.

---

## ğŸ§© Abschnitt 9 â€“ Hausaufgabe / Experiment

Erweitere deinen Ping-Workflow:

1. ErgÃ¤nze eine **Function-Node**, die dem LLM-Output einen Zeitstempel anhÃ¤ngt.
2. Sende diesen Output zusÃ¤tzlich per **Email-Node** an dich.
3. Logge die Ausgabe in eine Datei auf deinem System (`Write Binary File`-Node).

Ziel: Du dokumentierst jede Kommunikation deines Agenten automatisch â€“ ein Schritt Richtung Nachvollziehbarkeit und Evaluierung.

---

## ğŸš¨ Abschnitt 9 â€“ Debugging-Hinweise fÃ¼r n8n

### Node-Verbindungen funktionieren nicht

**Problem:** Nodes sind verbunden, aber Daten kommen nicht an
**LÃ¶sung:**

- Klicke auf "Test Step" bei jedem Node einzeln
- PrÃ¼fe im Debug-Panel: Sind die JSON-Felder korrekt benannt?
- Tipp: `{{$json["feldname"]}}` statt `{{$json.feldname}}` bei Sonderzeichen

### Webhook gibt 404 zurÃ¼ck

**Problem:** `POST http://localhost:5678/webhook/test` â†’ 404
**LÃ¶sung:**

- n8n Workflow muss **aktiviert** sein (Toggle oben rechts)
- Webhook-URL kopieren (Button im Webhook-Node)
- Test mit curl:
  ```bash
  curl -X POST -H "Content-Type: application/json" -d '{"test":"data"}' [WEBHOOK-URL]
  ```

### "Variable not found" Fehler

**Problem:** `{{$json.symbol}}` fÃ¼hrt zu Fehler
**Debug-Strategie:**

1. Execution-Log Ã¶ffnen â†’ Node anklicken â†’ JSON-Output prÃ¼fen
2. Function-Node vorschalten:
   ```javascript
   return [$input.all()];
   ```
   Zeigt komplette Datenstruktur
3. Korrekte Referenz verwenden: `{{$json["symbol"]}}` oder `{{$items("NodeName")[0].json.symbol}}`

### JSON-Explorer fÃ¼r unbekannte Datenstrukturen

Wenn du nicht weiÃŸt, welche Daten ankommen:

```javascript
console.log("=== DEBUG START ===");
console.log("Input Items Count:", $input.all().length);
console.log("First Item:", JSON.stringify($input.first(), null, 2));
console.log("All JSON keys:", Object.keys($json));
console.log("=== DEBUG END ===");
return [$json];
```

---

## âœ… Zusammenfassung

Nach Kapitel 2 kannst du:

- n8n starten, bedienen und Workflows debuggen,
- Telegram- und OpenAI-Nodes nutzen,
- und hast deinen ersten LLM-Agenten Ã¼ber einen Webhook getriggert.

Im nÃ¤chsten Kapitel wirst du lernen, **LLMs gezielt als Datenanalysten** einzusetzen: Marktdaten abrufen, strukturieren und bewerten lassen.
