# ğŸ“˜ Kapitel 8 â€“ Performance-Optimierung und Fehler-Recovery

**Lernziel:**  
Nach dieser Lektion kannst du deine Workflows so strukturieren, dass sie **schneller**, **stabiler** und **ausfallsicherer** laufen.  
Du lernst, wie du FlaschenhÃ¤lse erkennst, Logs zur Laufzeitanalyse nutzt und deinen Agenten nach Fehlern automatisch wiederherstellen lÃ¤sst.

---

## ğŸ§© Abschnitt 1 â€“ Warum Performance im Multi-Agent-System kritisch ist

Mit jedem zusÃ¤tzlichen Node steigen:
- AusfÃ¼hrungszeit  
- API-Aufrufe  
- Tokenkosten  
- Fehlerwahrscheinlichkeit  

Ziel ist also **Effizienz ohne Funktionsverlust**.  
Ein performanter Flow ist nicht der kÃ¼rzeste, sondern der, der die **richtigen Aufgaben am richtigen Ort** ausfÃ¼hrt â€“ mÃ¶glichst parallel, mit klar definierten RÃ¼ckfÃ¤llen (Fallbacks), falls etwas schieflÃ¤uft.

---

## âš™ï¸ Abschnitt 2 â€“ Performance messen

n8n liefert im *Execution Panel* bereits Basisdaten:
- **Execution time:** Gesamtlaufzeit pro Run  
- **Node timings:** Dauer pro Node  
- **Memory footprint:** angezeigt in Logs  

### Debugging-Tipp:
ErgÃ¤nze in jedem kritischen Node eine Messung der Laufzeit:
```javascript
const start = Date.now();
// â€¦ dein Code â€¦
const duration = Date.now() - start;
return [{ ...$json, duration_ms: duration }];
```
So kannst du im Data Store spÃ¤ter Laufzeiten auswerten.

Optional: lege eine eigene Tabelle `performance_logs` an mit Feldern:
`workflow`, `node`, `duration_ms`, `timestamp`.

---

## ğŸ§  Abschnitt 3 â€“ Parallelisierung: schneller durch Batches

Wenn dein Flow mehrere unabhÃ¤ngige Symbol-Analysen ausfÃ¼hrt (z.â€¯B. BTC, EUR/USD, Gold), kannst du sie parallel laufen lassen.

Nutze:
- **Split In Batches Node:** um Daten auf mehrere Flows zu verteilen.  
- **Workflow Execute Node:** um Sub-Flows parallel zu starten.  

Beispiel:
```
[Webhook Trigger]
   â†“
[Function â†’ Liste der Symbole]
   â†“
[Split In Batches â†’ Workflow Execute]
```

Jeder Sub-Flow behandelt ein Symbol â€“ so halbierst du Laufzeit bei stabiler API-Performance.

**Debugging-Hinweis:**  
Beobachte die *Execution IDs* im Dashboard. Wenn eine Batch fehlschlÃ¤gt, kannst du sie gezielt neu starten, ohne den ganzen Run zu wiederholen.

---

## ğŸ’¡ Abschnitt 4 â€“ Fehler-Recovery: dein Agent heilt sich selbst

Fehler sind unvermeidlich, aber sie dÃ¼rfen den Gesamtprozess nicht stoppen.  

### Strategie 1: Error Workflow  
Wie schon in Kapitel 7 erwÃ¤hnt â€“ dieser Workflow wird bei jedem Fehler getriggert.  
Erstelle ein standardisiertes Recovery-Schema:

```
[Error Trigger]
   â†“
[Function â†’ Fehlerklassifikation]
   â†“
[Switch â†’ Entscheidung]
   â†“
[Retry Workflow] oder [Notify Telegram]
```

**Function Node (Beispiel):**
```javascript
const e = $json.error || {};
if (e.message.includes("timeout")) return [{ type: "retry" }];
if (e.message.includes("invalid JSON")) return [{ type: "parse_error" }];
return [{ type: "notify" }];
```

So unterscheidet dein System automatisch zwischen â€nochmal versuchenâ€œ und â€manuell eingreifenâ€œ.

---

## ğŸ§© Abschnitt 5 â€“ Wiederholungslogik (Retries)

In normalen Nodes kannst du unter *Settings â†’ Max. Tries* Wiederholungen aktivieren.  
Alternativ per Node-Logik:
```javascript
let attempts = 0;
let success = false;
while (!success && attempts < 3) {
  try {
    // API-Aufruf
    success = true;
  } catch (err) {
    attempts++;
    console.warn(`Retry ${attempts}`);
    await new Promise(r => setTimeout(r, 2000)); // Pause zwischen Versuchen
  }
}
return [{ attempts }];
```

Diese Schleifen-Nodes schÃ¼tzen dich vor kurzzeitigen Netzwerkproblemen.

---

## âš™ï¸ Abschnitt 6 â€“ Logging fÃ¼r Debugging und Analyse

Lege fÃ¼r jede wichtige AusfÃ¼hrung eine Log-Datei an, z.â€¯B. im `logs/`-Ordner deines Projekts.

**Function Node:**
```javascript
const fs = require("fs");
const logPath = `/data/logs/run_${new Date().toISOString()}.json`;
fs.writeFileSync(logPath, JSON.stringify($json, null, 2));
return $input.all();
```

Alternativ: nutze den n8n-Data-Store oder ein externes Tool (z.â€¯B. Loki, Grafana, InfluxDB).  
Logs sind Gold â€“ sie sind der Unterschied zwischen â€Fehlerâ€œ und â€Erkenntnisâ€œ.

---

## ğŸ§© Abschnitt 7 â€“ Ressourcen sparen mit Conditional Execution

Jede LLM-Abfrage kostet Zeit und Tokens.  
Deshalb: nur dann anfragen, wenn neue Daten vorliegen oder sich Marktbedingungen stark geÃ¤ndert haben.

**Function Node (VorprÃ¼fung):**
```javascript
if ($json.lastUpdate && Date.now() - new Date($json.lastUpdate).getTime() < 60000) {
  return []; // Ãœberspringe, wenn zu frisch
}
return [$json];
```

So vermeidest du unnÃ¶tige API-Calls.

---

## ğŸ§© Abschnitt 8 â€“ Praxis: Recovery-Flow mit automatischer Wiederaufnahme

1. Baue deinen **Error Workflow**, der Timeouts erkennt und fehlgeschlagene Runs neu startet.  
2. Implementiere Retry-Schleifen in kritischen Nodes.  
3. Logge alle Fehler systematisch in `error_log` Data Store.  
4. ErgÃ¤nze einen Telegram-Node, der bei dreimaligem Fehlschlag eine Nachricht sendet.  
5. FÃ¼hre Stresstest aus: 10 parallele AusfÃ¼hrungen â†’ prÃ¼fe Logs auf AusfÃ¤lle.  

**Debugging-Checkliste:**
- Werden Fehlermeldungen im Error Workflow sichtbar?  
- Funktioniert Retry korrekt?  
- Bleibt der Agent nach Recovery konsistent (keine doppelten EintrÃ¤ge)?  

---

## ğŸ§­ Abschnitt 9 â€“ Reflexion

- Wie erkennst du in Logs die wahren Ursachen (Logikfehler vs. externe AusfÃ¤lle)?  
- Welche Schwachstelle ist bei dir am anfÃ¤lligsten fÃ¼r Timeouts?  
- Wie wÃ¼rdest du mit zu hohen Tokenkosten umgehen â€“ eher caching oder weniger Detail im Prompt?

---

## ğŸ§© Abschnitt 10 â€“ Hausaufgabe / Experiment

1. Erstelle einen Recovery-Workflow mit Telegram-Benachrichtigung.  
2. Simuliere absichtlich einen Fehler (z.â€¯B. ungÃ¼ltigen JSON-Response) und beobachte die Recovery.  
3. Miss die Laufzeiten einzelner Nodes und speichere sie.  
4. Reduziere Laufzeit durch Batch-AusfÃ¼hrung oder VorprÃ¼fung.  
5. Notiere vor und nach der Optimierung: â€Durchschnittliche Laufzeitâ€œ, â€Tokenverbrauchâ€œ, â€Fehlerrateâ€œ.

---

## âœ… Zusammenfassung

Nach Kapitelâ€¯8 kannst du:
- Flows auf Effizienz und StabilitÃ¤t optimieren,  
- Fehler erkennen, loggen und automatisch behandeln,  
- Ressourcenverbrauch steuern,  
- und mit Logs gezielt Performance verbessern.  

Im nÃ¤chsten Kapitel (9) lernst du, wie du aus diesen Logs und Feedbacks **automatische QualitÃ¤tsmetriken** generierst â€“ um deinen Agenten langfristig zu bewerten und zu verbessern.