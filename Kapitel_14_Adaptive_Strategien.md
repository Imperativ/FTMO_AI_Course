# üìò Kapitel 14 ‚Äì Adaptive Strategien und kontinuierliches Lernen

**Lernziel:**  
Nach dieser Lektion kannst du deinen Agenten so erweitern, dass er aus seinen eigenen Ergebnissen lernt, Strategien dynamisch anpasst und damit seine Performance im Zeitverlauf verbessert ‚Äì unter voller Kontrolle und Nachvollziehbarkeit.

---

## üß© Abschnitt 1 ‚Äì Was bedeutet ‚ÄûAdaptivit√§t‚Äú im Agentensystem?

Ein adaptives System erkennt Muster in den eigenen Erfolgen und Fehlschl√§gen und nutzt diese Information zur Selbstoptimierung.  
Das Ziel ist **kontrollierte Selbstanpassung**, nicht autonomes Umschreiben von Regeln.

In deinem FTMO-Agenten bedeutet das:
- Lernen aus historischen Trades und Evaluationslogs  
- dynamische Anpassung von Parametern wie Risiko, Zeithorizont, oder Entscheidungsschwellen  
- Erprobung kleiner Ver√§nderungen mit klarer Dokumentation (‚Äûexperimentelle Branches‚Äú)

---

## ‚öôÔ∏è Abschnitt 2 ‚Äì Feedback-Loop aus Logs und Metriken

Dein System produziert bereits reichlich Daten: Winrate, Drawdown, Latenz, Tokenverbrauch.  
Diese Daten sind der Rohstoff f√ºr Lernen.

Ein typischer Feedback-Loop:
```
[Logs + Reports]
   ‚Üì
[Evaluation Flow (aus Kap. 12)]
   ‚Üì
[LLM Node ‚Üí Musteranalyse]
   ‚Üì
[Decision Node ‚Üí Strategie-Update]
   ‚Üì
[Commit & Versioning]
```

**Function-Node Beispiel f√ºr Parameter-Anpassung:**
```javascript
const perf = $json;
let riskMultiplier = 1.0;

if (perf.winrate > 0.65 && perf.profitFactor > 1.5) {
  riskMultiplier = 1.2; // vorsichtig erh√∂hen
} else if (perf.winrate < 0.5) {
  riskMultiplier = 0.8; // reduzieren
}

return [{ ...perf, newRiskMultiplier: riskMultiplier }];
```

**Debugging-Hinweis:**  
Achte darauf, dass Anpassungen erst nach ausreichender Datenmenge (> 30 Trades) erfolgen, um statistisches Rauschen zu vermeiden.

---

## üß† Abschnitt 3 ‚Äì Experimentelles Lernen mit Versions-Branches

Erstelle f√ºr jede gr√∂√üere Anpassung einen neuen Branch:
```bash
git checkout -b experiment_risk_v2
```

Darin testest du alternative Parameter oder Prompts.  
Wenn die Ergebnisse stabil besser sind ‚Üí Merge in Hauptzweig.  

**Debugging-Tipp:**  
Nutze in n8n ein Feld `experiment_tag` (z. B. ‚Äûrisk_v2‚Äú) in deinen Logs. So kannst du in der Evaluation zwischen Varianten unterscheiden.

---

## üí° Abschnitt 4 ‚Äì Selbst√ºberpr√ºfung durch LLM-Analysen

Setze ein LLM-Node ein, das historische Logs analysiert und qualitative Trends beschreibt:

**Prompt:**
```
Analysiere die letzten 100 Trades.
Bewerte die Konsistenz der Entscheidungslogik und erkenne wiederkehrende Muster bei Fehlschl√§gen.
Gib Vorschl√§ge f√ºr Parameteranpassungen im JSON-Format:
{"param":"risk_level","suggested_change":-0.1,"reason":"zu hohe Verlustserie bei hoher Volatilit√§t"}
```

**Debugging-Hinweis:**  
Beschr√§nke die Analyse auf objektive Metriken; vermeide unkontrollierte Ver√§nderungen, indem du jeden Vorschlag manuell best√§tigst oder in einem Review-Flow pr√ºfst.

---

## ‚öôÔ∏è Abschnitt 5 ‚Äì Adaptive Regeln in n8n

Implementiere adaptive Regeln mit Switch- oder IF-Nodes, basierend auf dynamischen Feldern:

```javascript
if ($json.volatility > 1.8 && $json.sentiment < 0.3) {
  $json.position = "avoid";
} else if ($json.trend === "bullish" && $json.risk < 0.7) {
  $json.position = "long";
} else {
  $json.position = "neutral";
}
return [$json];
```

Diese Regeln k√∂nnen w√∂chentlich durch den Evaluations-Flow aktualisiert werden.

---

## üß© Abschnitt 6 ‚Äì Langzeit-Monitoring und Drift-Erkennung

√úber Zeit k√∂nnen sich Marktbedingungen √§ndern ‚Äì dein Agent muss erkennen, wann alte Strategien nicht mehr passen.

### Erkenne Performance-Drift:
```javascript
const recent = $json.last30Days.winrate;
const previous = $json.last90Days.winrate;
if (recent < previous * 0.8) {
  throw new Error("Performance Drift detected ‚Äì Recalibration required");
}
```

F√ºge diese √úberwachung in den t√§glichen Cron-Report ein.

**Debugging-Hinweis:**  
Achte auf fehlerhafte Zeitfenster: Wenn die Logs L√ºcken enthalten, Drift-Vergleiche anhalten und L√ºcken im Data-Store schlie√üen.

---

## üí° Abschnitt 7 ‚Äì Automatische Dokumentation von Lernschritten

Erstelle bei jeder Anpassung einen Eintrag in `LEARNING_LOG.md`:

```
### [2025-11-05]
- Grundlage: Evaluation vom 03.11.‚Äì04.11.
- √Ñnderung: riskMultiplier +0.1
- Ergebnis nach 20 Trades: Winrate +4 %, Drawdown ‚àí2 %
- Bewertung: erfolgreich, in Version 1.4 √ºbernommen
```

**Debugging-Hinweis:**  
Automatisiere Eintragserstellung via Function-Node:
```javascript
const fs = require('fs');
fs.appendFileSync('./docs/LEARNING_LOG.md', `\n${new Date().toISOString()} ‚Äì ${$json.summary}`);
return $input.all();
```

---

## üß© Abschnitt 8 ‚Äì Praxis: Mini-Selbstlern-Cycle

1. F√ºhre Evaluation (Kap. 12) t√§glich automatisch aus.  
2. Analysiere Metriken ‚Üí LLM schl√§gt Parameter-Anpassung vor.  
3. Schreibe Vorschl√§ge in `LEARNING_LOG.md`.  
4. Best√§tige manuell oder √ºber Review-Node.  
5. √úbernehme nach Validierung in `risk_config.json`.  

So entsteht ein lernf√§higer, aber kontrollierter Agent.

---

## üß≠ Abschnitt 9 ‚Äì Reflexion

- Wann ist Lernen sinnvoll, wann gef√§hrlich (z. B. √úberanpassung)?  
- Wie viel Automatisierung w√ºrdest du zulassen?  
- Wie stellst du sicher, dass Experimente nachvollziehbar bleiben?  

---

## ‚úÖ Zusammenfassung

Nach Kapitel‚ÄØ14 kannst du:
- deinen Agenten zu einem adaptiven System erweitern,  
- Feedback-Loops aus Logs und Metriken einbauen,  
- automatische Lernvorschl√§ge ausf√ºhren und pr√ºfen,  
- und langfristig stabile, selbstkorrigierende Strategien entwickeln.  

Das n√§chste Kapitel (15) f√ºhrt diese Idee in die Zukunft: **Multi-Agent-Kollaboration und hybride Entscheidungsnetze**, in denen mehrere spezialisierte Systeme gemeinsam Marktentscheidungen treffen ‚Äì √§hnlich wie Teams aus Analysten, Bots und Strategiemodulen.