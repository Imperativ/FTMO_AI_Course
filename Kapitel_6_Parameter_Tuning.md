# ğŸ“˜ Kapitel 6 â€“ Parameter-Tuning und A/B-Vergleiche

**Lernziel:**  
Nach dieser Lektion kannst du deinen Agenten so erweitern, dass er **verschiedene Strategiekonfigurationen testet**, Ergebnisse protokolliert und bewertet.  
Du lernst, wie man mit A/B-Vergleichen experimentiert, Parameter automatisch variiert und auf Basis der gespeicherten Daten Performance misst.

---

## ğŸ§© Abschnitt 1 â€“ Warum Parameter-Tuning wichtig ist

Selbst gute Strategien verlieren, wenn sie starr bleiben.  
Die MÃ¤rkte verÃ¤ndern sich, LiquiditÃ¤t, VolatilitÃ¤t und Trader-Verhalten ebenfalls.  
Dein Ziel ist es daher nicht, â€die perfekte Einstellungâ€œ zu finden, sondern ein **System**, das Anpassung ermÃ¶glicht.  

Das Prinzip lautet:  
> *Optimierung durch strukturierte Variation â€“ nicht durch Intuition.*

Mit anderen Worten: du testest Varianten gezielt, beobachtest Ergebnisse, und wÃ¤hlst jene Parameter, die langfristig StabilitÃ¤t bringen.

---

## âš™ï¸ Abschnitt 2 â€“ Parameter als variable Inputs

In n8n kannst du Parameter dynamisch Ã¼bergeben â€“ ideal fÃ¼r systematisches Testen.  

Beispiel:  
Du mÃ¶chtest herausfinden, ob ein hÃ¶herer Stop-Loss-Abstand die Winrate verbessert.

**Function-Node (Parameter-Generator):**
```javascript
return [
  { variant: "A", stopLossPoints: 30, riskPercent: 0.02 },
  { variant: "B", stopLossPoints: 50, riskPercent: 0.02 }
];
```

Verbinde diesen Node mit deinem bestehenden **Analyse-Flow** Ã¼ber eine â€Split In Batchesâ€œ-Node, damit jede Variante separat getestet wird.

---

## ğŸ§  Abschnitt 3 â€“ A/B-Vergleichsstruktur

Ein typischer Testablauf sieht so aus:

```
[Trigger / Backtest-Start]
   â†“
[Function Node â†’ Parameter-Varianten]
   â†“
[Loop Ã¼ber Varianten]
   â†“
[Analyse & Entscheidung (LLM)]
   â†“
[Simulation oder Logging]
   â†“
[Data Store Insert (mit Variant-ID)]
```

In jeder Schleife wird eine Variante getestet.  
Speichere zusÃ¤tzlich zur normalen Signal-Info ein Feld `variant: "A"` oder `"B"` im Data Store, um die Ergebnisse spÃ¤ter trennen zu kÃ¶nnen.

---

## ğŸ§© Abschnitt 4 â€“ Automatisierte Auswertung in n8n

Sobald du mehrere Varianten protokolliert hast, kannst du direkt in n8n die Performance vergleichen.

**Data Store Query + Function-Node:**
```javascript
const items = $input.all();
const grouped = {};
for (const i of items) {
  const v = i.json.variant || "unknown";
  grouped[v] = grouped[v] || { total: 0, wins: 0, losses: 0 };
  grouped[v].total++;
  if (i.json.outcome === "TP") grouped[v].wins++;
  if (i.json.outcome === "SL") grouped[v].losses++;
}
const report = Object.keys(grouped).map(v => ({
  variant: v,
  winrate: grouped[v].wins / grouped[v].total,
  total: grouped[v].total
}));
return report;
```

Damit erhÃ¤ltst du sofort die Erfolgsquote pro Variante.  
Das Ergebnis kannst du per Telegram, E-Mail oder Dashboard visualisieren lassen.

---

## ğŸ’¡ Abschnitt 5 â€“ Parameterwahl durch LLM-Auswertung

Das aktuelle LLM-Modell kann selbst einfache Mustererkennung Ã¼bernehmen.  
Wenn du willst, dass dein Agent VerbesserungsvorschlÃ¤ge macht, gib ihm die aggregierten Ergebnisse als Input:

```
Analysiere folgende Testergebnisse:
Variante A: Winrate 0.52, Drawdown 3.1 %
Variante B: Winrate 0.64, Drawdown 5.5 %
Welche Variante bietet langfristig das bessere Chance/Risiko-VerhÃ¤ltnis?
```

Der Agent wird nicht â€optimierenâ€œ, aber qualitativ einschÃ¤tzen, welche Kombination robuster erscheint.  
Solche RÃ¼ckmeldungen helfen dir, menschliche und maschinelle Perspektiven zu kombinieren.

---

## âš ï¸ Abschnitt 6 â€“ Achte auf statistische Fallstricke

- **Zu kleine Stichprobe:** Unter 30 Trades pro Variante ist fast jede Erkenntnis Zufall.  
- **Survivorship Bias:** Wenn du nur erfolgreiche Phasen analysierst, tÃ¤uscht StabilitÃ¤t.  
- **Overfitting:** Je enger du an vergangene Daten anpasst, desto schlechter performt die Strategie live.  
- **Paralleltests:** FÃ¼hre nie zu viele Varianten gleichzeitig, sonst verwischst du die Ergebnisse.

ErfahrungsgemÃ¤ÃŸ ist *langsames, kontrolliertes Testen* der SchlÃ¼ssel.

---

## ğŸ§© Abschnitt 7 â€“ Praxis: Dein erster A/B-Workflow

1. Kopiere deinen Flow aus Kapitel 5.  
2. FÃ¼ge vor dem LLM-Node einen **Function-Node** hinzu, der zwei Parameter-Sets erzeugt (z.â€¯B. Stop-Loss 30 vs. 50).  
3. FÃ¼ge einen **Split In Batches-Node** ein, damit jede Variante separat lÃ¤uft.  
4. ErgÃ¤nze im **Data Store Insert** ein Feld `variant`.  
5. Nach einigen DurchlÃ¤ufen: Query-Node + Function-Node â†’ Aggregation der Winrates.  
6. Sende die Ergebnisse per Telegram.

Optional: Baue einen dritten Flow, der automatisch den besten Parameter anzeigt, sobald >â€¯30 Trades pro Variante erreicht sind.

---

## ğŸ§­ Abschnitt 8 â€“ Reflexion

- Welche Parameter sind bei dir am einflussreichsten?  
- Ab wann wÃ¼rdest du sagen, dass eine Variante â€statistisch signifikant besserâ€œ ist?  
- Wie kÃ¶nntest du den Test planbar automatisieren, ohne die Kontrolle zu verlieren?

Solche Ãœberlegungen machen den Unterschied zwischen Experiment und Optimierung.

---

## ğŸ§© Abschnitt 9 â€“ Hausaufgabe / Experiment

1. FÃ¼hre einen A/B-Test mit zwei Varianten deines bisherigen Systems durch (z.â€¯B. Stop-Loss 30 vs. 50).  
2. Dokumentiere mindestens 10 Signale je Variante.  
3. Erstelle eine Winrate-Statistik in n8n.  
4. Frage das LLM-Modell nach einer qualitativen EinschÃ¤tzung.  
5. Trage Beobachtungen in deine Kursmappe ein.

---

## âœ… Zusammenfassung

Nach Kapitelâ€¯6 kannst du:
- Parameter dynamisch variieren und testen,  
- A/B-Vergleiche in n8n strukturieren,  
- Ergebnisse automatisch auswerten,  
- und dein LLM-System als beratende Instanz einbinden.  

Im nÃ¤chsten Kapitel lernst du, wie du **mehrere spezialisierte Agentenrollen** kombinierst â€“ Analyst, Risiko-Manager und Strategieberater â€“ um deinen FTMO-Assistenten modular zu machen.